<form theme="dark" version="1.1">
  <label>Splunk Admin - Checks - General</label>
  <fieldset submitButton="false">
    <input type="time" token="splunk_issues_timerange">
      <label>Time Range</label>
      <default>
        <earliest>-7d@h</earliest>
        <latest>now</latest>
      </default>
    </input>
  </fieldset>
  <row>
    <panel>
      <title>OS - Core Dumps Disabled</title>
      <table>
        <search>
          <query>index=_internal "WARN  ulimit - Core file generation disabled" sourcetype=splunkd (source=*splunkd.log) 
| stats count, earliest(_time) as earliest_time, latest(_time) AS latest_time by host 
| `cs_human_readable_time_format(earliest_time)`
| `cs_human_readable_time_format(latest_time)`
| sort - count</query>
          <earliest>$splunk_issues_timerange.earliest$</earliest>
          <latest>$splunk_issues_timerange.latest$</latest>
        </search>
        <option name="drilldown">none</option>
        <option name="refresh.display">progressbar</option>
      </table>
    </panel>
  </row>
  <row>
    <panel>
      <title>OS - Transparent Huge Pages is enabled</title>
      <table>
        <search>
          <query>index=_internal "Linux transparent hugepage support, enabled=" sourcetype=splunkd source="*splunkd.log" enabled!="never"
| stats count, earliest(_time) as earliest_time, latest(_time) AS latest_time, latest(_raw) as sample_raw by host 
| `cs_human_readable_time_format(earliest_time)`
| `cs_human_readable_time_format(latest_time)`
| sort - count</query>
          <earliest>$splunk_issues_timerange.earliest$</earliest>
          <latest>$splunk_issues_timerange.latest$</latest>
        </search>
        <option name="drilldown">none</option>
        <option name="refresh.display">progressbar</option>
      </table>
      <html>
        <p>This configuration of transparent hugepages is known to cause serious runtime problems with Splunk. Typical symptoms include generally reduced performance and catastrophic breakdown in system responsiveness under high memory pressure. Please fix by setting the values for transparent huge pages to "madvise" or preferably "never" via sysctl, kernel boot parameters, or other method recommended by your Linux distribution.</p>
      </html>
    </panel>
  </row>
  <row>
    <panel>
      <title>OS - ulimit on Splunk enterprise servers is below 8192</title>
      <table>
        <search>
          <query>index=_internal "ulimit" "open files:" sourcetype=splunkd (source=*splunkd.log)
| rex "(?P&lt;nooffiles&gt;\d+) files" 
| where nooffiles&lt;8192
| stats count, earliest(_time) as earliest_time, latest(_time) AS latest_time, latest(_raw) as sample_raw by host 
| append [search index=_internal log_level=WARN sourcetype=splunkd (source=*splunkd.log) component=ulimit "Splunk may not work due to low file size limit" 
| stats count, earliest(_time) as earliest_time, latest(_time) AS latest_time, latest(_raw) as sample_raw by host ]
| `cs_human_readable_time_format(earliest_time)`
| `cs_human_readable_time_format(latest_time)`
| sort - count</query>
          <earliest>$splunk_issues_timerange.earliest$</earliest>
          <latest>$splunk_issues_timerange.latest$</latest>
        </search>
        <option name="drilldown">none</option>
        <option name="refresh.display">progressbar</option>
      </table>
      <html>
        <p>Splunk instances with file descriptor less than 8192 Or</p>
        <p>Universal forwarders that have the ulimit set too low for the number of file descriptors (ulimit -n)</p>
      </html>
    </panel>
  </row>
  <row>
    <panel>
      <title>OS - Splunk Server with Resource Starvation</title>
      <table>
        <search>
          <query>index=_internal sourcetype=splunkd source=*splunkd.log "Might indicate hardware or splunk limitations" OR "took longer than" NOT "Might indicate slow ldap server."
| rex "^[\d-]+ [\d:\.]+( )+[\+-]?\d+( )+[^ ]+( )+(?P&lt;componentAndArea&gt;([^ ]+( )+){3}).*\((?P&lt;number&gt;\d+) milliseconds" 
| rex "^[\d-]+ [\d:\.]+( )+[\+-]?\d+( )+[^ ]+( )+(?P&lt;componentAndArea2&gt;DispatchManager\s+([^ ]+( )+){3}).*elapsed_ms=(?P&lt;number3&gt;\d+)" 
| rex "Spent (?P&lt;number2&gt;\d+)"
| rex "reaping (?P&lt;area&gt;([^ ]+ ){2})"
| eval componentAndArea=case(isnotnull(componentAndArea2),componentAndArea2,isnull(componentAndArea),component . "_" . area,1=1,componentAndArea), number=coalesce(number,number2,number3)
| stats count, earliest(_time) as earliest_time, latest(_time) AS latest_time, avg(number) AS avgTimeInSeconds, max(number) AS maxTimeInSeconds by host, componentAndArea
| `cs_human_readable_time_format(earliest_time)`
| `cs_human_readable_time_format(latest_time)`
| sort - count
| eval avgTimeInSeconds=round(avgTimeInSeconds/1000,2), maxTimeInSeconds=round(maxTimeInSeconds/1000,2)</query>
          <earliest>$splunk_issues_timerange.earliest$</earliest>
          <latest>$splunk_issues_timerange.latest$</latest>
        </search>
        <option name="drilldown">none</option>
        <option name="refresh.display">progressbar</option>
      </table>
    </panel>
  </row>
  <row>
    <panel>
      <title>Data Loss on shutdown</title>
      <table>
        <search>
          <query>index=_internal sourcetype=splunkd source=*splunkd.log "Forcing TcpOutputGroups to shutdown after timeout"
| stats count, earliest(_time) as earliest_time, latest(_time) AS latest_time, latest(_raw) as sample_raw by host 
| `cs_human_readable_time_format(earliest_time)`
| `cs_human_readable_time_format(latest_time)`
| sort - count</query>
          <earliest>$splunk_issues_timerange.earliest$</earliest>
          <latest>$splunk_issues_timerange.latest$</latest>
        </search>
        <option name="drilldown">none</option>
        <option name="refresh.display">progressbar</option>
      </table>
      <html>
        <p>Waiting for TcpOutputGroups to shutdown followed by the message 'Forcing TcpOutputGroups to shutdown after timeout' is not something that can be controlled as of 7.2.1. It also generally correlates with data loss as the forwarder in question could not get the data through the queues and out of the forwarder/indexer before shutdown. Increasing parsingQueue/aggQueue or similar may help in this scenario.</p>
      </html>
    </panel>
  </row>
  <row>
    <panel>
      <title>Email Sending Failures</title>
      <table>
        <search>
          <query>index=_internal "stderr from " python* sendemail.py sourcetype=splunkd (source=*splunkd.log)
| eval message=coalesce(message,event_message)
| rex "ssname=(?P&lt;savedsearch&gt;[^\"]+)"
| rex "stderr from '[^']+':\s+(?P&lt;error&gt;.*)"
| rex field=results_file ".*/dispatch/[^_]+__(?P&lt;user&gt;[^_]+)"
| stats count, earliest(_time) as earliest_time, latest(_time) AS latest_time, values(error) as errors, latest(_raw) as sample_raw by host, savedsearch, user
| eval some_errors=mvindex(errors, 0, 3) | fields - errors
| `cs_human_readable_time_format(earliest_time)`
| `cs_human_readable_time_format(latest_time)`
| sort - count</query>
          <earliest>$splunk_issues_timerange.earliest$</earliest>
          <latest>$splunk_issues_timerange.latest$</latest>
        </search>
        <option name="drilldown">none</option>
        <option name="refresh.display">progressbar</option>
      </table>
    </panel>
  </row>
  <row>
    <panel>
      <title>Losing Contact With Master Node</title>
      <table>
        <search>
          <query>index=_internal sourcetype=splunkd (source=*splunkd.log) (TERM(CMSearchHead) OR TERM(GenerationGrabber) OR (TERM(CMMasterProxy) TERM(down))) OR (TERM(cluster) TERM(master) TERM(CMSlave) TERM(WARN) OR TERM(ERROR))
| fillnull master value="N/A"
| rex "(?s)^(\S+\s+){3}(?P&lt;error&gt;.*)"
| stats count, earliest(_time) as earliest_time, latest(_time) AS latest_time, values(host) as hosts by error, master
| `cs_human_readable_time_format(earliest_time)`
| `cs_human_readable_time_format(latest_time)`
| where (match(error,"GenerationGrabber") AND count&gt;10) OR (match(error, "(CMSearchHead|CMMasterProxy|CMSlave)") AND count&gt;1)</query>
          <earliest>$splunk_issues_timerange.earliest$</earliest>
          <latest>$splunk_issues_timerange.latest$</latest>
        </search>
        <option name="drilldown">none</option>
        <option name="refresh.display">progressbar</option>
      </table>
      <html>
        <p>Either the master is down or the indexers are having issues contacting the master or search head to master is having issues.</p>
      </html>
    </panel>
  </row>
  <row>
    <panel>
      <title>Splunkd Log Messages for Admins</title>
      <table>
        <search>
          <query>index=_internal (sourcetype=splunkd (source=*splunkd.log) 
    TERM(WARN) OR TERM(ERROR) TERM(MongoModificationsTracker) OR TERM(SearchOperator:kv) OR TERM(AuditTrailManager) OR TERM(IniFile) OR TERM(GetBundleListTransaction) OR TERM(GenericConfigKeyHandler) OR TERM(AuthorizationManager) OR TERM(GetRemoteAuthToken) OR TERM(DistributedPeer) OR (TERM(Archiver) TERM(Permission)) OR TERM(GetIndexListTransaction) OR (TERM(DistributedPeerManager) TERM(Timeout)) OR TERM(CalcFieldProcessor) OR TERM(FieldAliaser) OR (TERM(SearchScheduler) OR TERM(DispatchManager) "minimum free disk space") OR TERM(ApplicationUpdater) OR (TERM(ScopedLDAPConnection) NOT "Might indicate slow ldap server" NOT "Converting non-UTF-8 value to") OR TERM(regexExtractionProcessor) OR (TERM(ProcessTracker) NOT TERM(ConfMetrics)) OR TERM(ConfReplication) OR TERM(TailingProcessor) OR "Invalid cron_schedule" OR "Persistent file" OR "Too many indexes" OR "UserManagerPro - Strategy" OR TERM(SearchProcessMemoryTracker) OR TERM(SSLOptions) OR (TERM(SHCRepJob) TERM(misspelled)) OR TERM(PivotEvaluator) OR TERM(PropertiesMap) OR TERM(HTTPAuthManager) OR TERM(X509Verify) OR TERM(FilesystemChangeWatcher) OR TERM(PropsKeyHandler) OR TERM(IndexProcessor) OR TERM(BundleArchiver) OR (TERM(ApplicationManager) NOT "Skipping update check for app id" NOT "This is expected if you push an app from the cluster master") OR TERM(ISplunkDispatch) OR TERM(TcpInputConfig) OR (TERM(CollectionConfHandler) TERM(Bad) OR TERM(reload)) OR TERM(SLConstants) OR TERM(AdminHandler:AuthenticationHandler) OR (TERM(DispatchManager) NOT (TERM(failedtostart) OR TERM(quota) OR TERM(QUEUED) OR TERM(concurrency) OR TERM(concurrently))) OR TERM(KVStoreBulletinBoardManager) OR TERM(CMRestIndexerDiscoveryHandler)
OR TERM(KVStoreConfigurationProvider) OR TERM(LMMasterRestHandler) OR TERM(LMHttpUtil) OR (TERM(DatabaseDirectoryManager) TERM(Detecting)) OR (TERM(No) TERM(space) NOT TERM(SHCRepJob) NOT TERM(DispatchManager)) OR (TERM(KVStorageProvider) TERM(corrupted)) OR (TERM(baseline) TERM(configuration) TERM(replicating)) OR TERM(LMTracker) OR TERM(IndexerDiscoveryHeartbeatThread) OR TERM(ModularUtility) OR TERM(ScriptRestHandler) OR (TERM(KVStorageProvider) TERM(servers)) OR (TERM(S3Client) TERM(httpStatusCode)) OR TERM(BucketReplicator) 
OR TERM(WorkloadConfig) OR "WARN  loader" OR "ERROR loader" OR (TERM(AdminHandler:AuthenticationHandler) TERM(reasonable))
OR (TERM(KVStoreLookup) OR TERM(SingleLookupDriver) OR TERM(outputcsv) OR TERM(SearchOperator:inputcsv) NOT "You have insufficient privileges" NOT "KV Store initialization" NOT "KV Store is shutting down" NOT "Found no results" NOT "lookup context" NOT "searchparsetmp" NOT "Invalid argument" NOT "must be followed by a search clause") OR TERM(ConfigEncryptor) OR TERM(AesGcm)
 OR TERM(DeploymentServer) OR TERM(MongodRunner) OR (TERM(DS_DC_Common) NOT "attributes cannot be handled by WebUI") 
 NOT ("Configuration from app" "does not support reload")) OR (sourcetype=scheduler source=*scheduler.log TERM(AlertNotifier) TERM(WARN))
 OR (sourcetype=splunkd (source=*splunkd.log) TERM(INFO) (TERM(IndexWriter) TERM(paused))) OR (TERM(event=reclaimMemory) TERM(IndexProcessor) OR TERM(StreamingBucketBuilder)) 
| eval message=coalesce(message,event_message) 
| rex mode=sed field=message "s/^\([^\)]+\)\s+(ProcessTracker\s+-\s+)?(\([^\)]+\)\s+)?IndexConfig/IndexConfig/g"
| rex mode=sed field=message "s/^sid:[^ ]+//g"
| rex mode=sed field=message "s/snapshot:\s+[^;]+;\s+Configurations changed while generating snapshot, original_latest_change=[^,]+, new_latest_change=[^,]+/snapshot: &lt;bundledir&gt; Configurations changed while generating snapshot original_latest_change=&lt;removed&gt;, new_latest_change=&lt;removed&gt;/"
| rex mode=sed field=message "s/Error getting modtime:\s+[^:]+/Error getting modtime: &lt;dir&gt;/g"
| rex field=message mode=sed "s/uri=(https?:\/\/([^\/]+\/){4})\S+/uri=\1/"
| rex field=message mode=sed "s/(&lt;Resource&gt;(\/[^\/]+){3}\/)[^&lt;]+/\1/"
| rex field=message mode=sed "s/&lt;RequestId&gt;[^&lt;]+&lt;\/RequestId&gt;/&lt;RequestId&gt;removed&lt;\/RequestId&gt;/"
| rex field=message mode=sed "s/transactionId=\S+\s+rTxnId=\S+/transactionId=removed rTxnId=removed/"
| rex field=message mode=sed "s/snapshot exists at op_id=\S+/snapshot exists at op_id=removed/"
| rex field=message mode=sed "s/(search_id=\"[^_]+_+[^_]+)[^\"]+/\1/"
| rex field=message mode=sed "s/bid=\S+/bid=?/" 
| stats count, earliest(_time) as earliest_time, latest(_time) AS latest_time, values(component) AS component, values(log_level) AS log_level, latest(_raw) as sample_raw by host, message
| `cs_human_readable_time_format(earliest_time)`
| `cs_human_readable_time_format(latest_time)`
| sort - count</query>
          <earliest>$splunk_issues_timerange.earliest$</earliest>
          <latest>$splunk_issues_timerange.latest$</latest>
        </search>
        <option name="drilldown">none</option>
        <option name="refresh.display">progressbar</option>
      </table>
      <html>
        <p>IndexWriter - May relate to maxConcurrentOptimizes in indexes.conf or perhaps maxRunningProcessGroups or spikes in data-per indexer</p>
        <p>IndexProcessor,reclaimMemory - May relate to memPoolMB / maxMemMB setting in indexes.conf or the IndexWriter getting paused</p>
      </html>
    </panel>
  </row>
</form>